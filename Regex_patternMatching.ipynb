{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOA2sj+qaCxueSwi6bG6RtM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MehraeenTimas/nlp-course/blob/main/Regex_patternMatching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TF_0SslONlY2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVA4WIAmK4Br"
      },
      "source": [
        "## 4. Regex for Pattern Matching\n",
        "\n",
        "Regex for pattern matching is a powerful technique to extract or filter specific text patterns. With NLTK, you can leverage its RegexpTokenizer to tokenize text based on custom regex patterns, while spaCyâ€™s Matcher enables regex-like matching within its robust linguistic framework.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXL-nbm1K59y",
        "outputId": "8e158c87-24cf-4150-f4af-bce1bbec207c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Regex Tokens: ['Hello', 'world', 'This', 'is', 'an', 'example', 'email', 'example', 'com', 'phone', '123', '456', '7890']\n"
          ]
        }
      ],
      "source": [
        "# NLTK Regex Example\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "text = \"Hello world! This is an example: email@example.com, phone: 123-456-7890.\"\n",
        "\n",
        "# Define a tokenizer that captures alphanumeric words\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "tokens = tokenizer.tokenize(text)\n",
        "print(\"NLTK Regex Tokens:\", tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7FQfmQAbfOK",
        "outputId": "3033a4fd-80b6-4067-f378-6298fd68cb9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matched token: Hello\n",
            "Matched token: This\n",
            "Matched token: Example\n"
          ]
        }
      ],
      "source": [
        "# spaCy Regex Example\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "# Load the small English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Define a regex-based pattern: match tokens that start with a capital letter\n",
        "pattern = [{\"TEXT\": {\"REGEX\": \"^[A-Z][a-z]+\"}}]\n",
        "matcher.add(\"CAPITAL_PATTERN\", [pattern])\n",
        "\n",
        "text = \"Hello world! This is an Example sentence.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "# Apply the matcher and print matched tokens\n",
        "matches = matcher(doc)\n",
        "for match_id, start, end in matches:\n",
        "    span = doc[start:end]\n",
        "    print(\"Matched token:\", span.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5Xl8N93bpEd",
        "outputId": "02fb7ac3-6801-4485-c6c7-d16dcf073c75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected Emails: ['admin.support_34@example.com', 'sales-dep@company.org']\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "text_emails = \"Contact us at admin.support_34@example.com or sales-dep@company.org for inquiries.\"\n",
        "\n",
        "# Example 1: Email Detection\n",
        "email_pattern = r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\"  # Regex for email matching\n",
        "\n",
        "emails = re.findall(email_pattern, text_emails)\n",
        "print(\"Detected Emails:\", emails)\n"
      ]
    }
  ]
}