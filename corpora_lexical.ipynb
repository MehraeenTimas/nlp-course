{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNWHiNZXY2l6Gm4er9ICAKg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MehraeenTimas/nlp-course/blob/main/corpora_lexical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "breyPFDzL2Ld"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGyHPx81Zqt1"
      },
      "source": [
        "## 2. Corpora and Lexical Resources\n",
        "Corpora and Lexical Resources are essential for understanding language structure and semantics. They provide extensive collections of texts (corpora) and structured word relationships (lexical databases) that support tasks like language modeling, semantic analysis, and more.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDxc7B1xaUJc",
        "outputId": "d0a52bcc-7f31-499f-af3a-58cbe75d09cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WordNet Synsets for 'computer': [Synset('great.n.01'), Synset('great.s.01'), Synset('great.s.02'), Synset('great.s.03'), Synset('bang-up.s.01'), Synset('capital.s.03'), Synset('big.s.13')]\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "# Retrieve synsets for the word 'computer'\n",
        "synsets = wn.synsets('great')\n",
        "print(\"WordNet Synsets for 'computer':\", synsets)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddu1Bb5rZqbd",
        "outputId": "f33c557e-4988-4c35-87e4-b529d08e3e54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gutenberg Files: ['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import gutenberg\n",
        "# List available files in the Gutenberg corpus\n",
        "print(\"Gutenberg Files:\", gutenberg.fileids())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUjT-FsGafwM"
      },
      "source": [
        "### spaCy Lexical Resources\n",
        "While spaCy does not include separate corpora like NLTK, its language models (e.g., en_core_web_sm) incorporate rich lexical data, including vocabulary, part-of-speech tags, and dependency structures.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KL3mBlBLadc4",
        "outputId": "59e52541-f9df-4240-f99e-1c0ff967e3c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token: Natural, Lemma: Natural, POS: PROPN, Dep: compound\n",
            "Token: Language, Lemma: Language, POS: PROPN, Dep: compound\n",
            "Token: Processing, Lemma: Processing, POS: PROPN, Dep: nsubj\n",
            "Token: is, Lemma: be, POS: AUX, Dep: ROOT\n",
            "Token: fun, Lemma: fun, POS: ADJ, Dep: acomp\n",
            "Token: and, Lemma: and, POS: CCONJ, Dep: cc\n",
            "Token: educational, Lemma: educational, POS: ADJ, Dep: conj\n",
            "Token: ., Lemma: ., POS: PUNCT, Dep: punct\n"
          ]
        }
      ],
      "source": [
        "doc = nlp(short_text)\n",
        "\n",
        "# Print token, lemma, POS tag, and dependency relation for each token\n",
        "for token in doc:\n",
        "    print(f\"Token: {token.text}, Lemma: {token.lemma_}, POS: {token.pos_}, Dep: {token.dep_}\")\n"
      ]
    }
  ]
}