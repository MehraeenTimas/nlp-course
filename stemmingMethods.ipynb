{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgJSqyZ0LdiZtYn69UALDs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MehraeenTimas/nlp-course/blob/main/stemmingMethods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkvx8DHKOdpt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8aXW-XgK8mV"
      },
      "source": [
        "## 6. Stemming Methods\n",
        "\n",
        "Stemming reduces words to their root forms by removing affixes, thus simplifying text for analysis and retrieval tasks. NLTK offers robust stemming algorithms like Porter, Lancaster, and Snowball. While spaCy focuses on lemmatization for morphological normalization, you can integrate NLTK's stemmers with spaCy's tokenization if stemming is required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykUhuPe_K88i",
        "outputId": "264e359b-e198-4680-ce79-5a5b164b3151"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Stemmed Words: ['run', 'runner', 'easili', 'studi', 'hardli', 'activ', 'ran']\n",
            "NLTK Snowball Words: ['run', 'runner', 'easili', 'studi', 'hardli', 'activ', 'ran']\n"
          ]
        }
      ],
      "source": [
        "# NLTK Stemming Example\n",
        "from nltk.stem import PorterStemmer, SnowballStemmer\n",
        "\n",
        "# Initialize the PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "sn = SnowballStemmer(language=\"english\")\n",
        "text = \"running runner easily study hardly activity ran\"\n",
        "words = nltk.word_tokenize(text)\n",
        "stems = [ps.stem(word) for word in words]\n",
        "\n",
        "sn_stems = [ps.stem(word) for word in words]\n",
        "print(\"NLTK Stemmed Words:\", stems)\n",
        "print(\"NLTK Snowball Words:\", sn_stems)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WY4Y4EQFLERL"
      },
      "outputs": [],
      "source": [
        "# Integrating NLTK Stemming with spaCy\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Load spaCy's small English model\n",
        "ps = PorterStemmer()\n",
        "\n",
        "doc = nlp(\"running runner easily run\")\n",
        "stems = [ps.stem(token.text) for token in doc]\n",
        "print(\"spaCy Integrated Stemmed Tokens:\", stems)\n"
      ]
    }
  ]
}