{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGtBXF3EmWh5wOW8NJ23OO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MehraeenTimas/nlp-course/blob/main/StopWords_filtering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gP70U8ZgOERF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcwWc9CULCG8"
      },
      "source": [
        "## 5. Stopwords Filtering\n",
        "\n",
        "Stopwords filtering involves removing commonly used words (e.g., \"the\", \"is\", \"at\") that often add little semantic value to text analysis. This process helps focus on more meaningful terms. NLTK offers a comprehensive list of stopwords, whereas spaCy incorporates an internal attribute for each token to determine if it is a stopword."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9NfGN-QbtuK",
        "outputId": "8bfca986-abe1-409e-eb60-fa4a41fc8786"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtered Words: ['simple', 'example', 'demonstrating', 'stopword', 'removal', 'natural', 'language', 'processing', '.']\n"
          ]
        }
      ],
      "source": [
        "# NLTK Stopwords Filtering\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "text = \"This is a simple example demonstrating stopword removal in natural language processing.\"\n",
        "words = nltk.word_tokenize(text)\n",
        "filtered_words = [word for word in words if word.lower() not in stopwords.words('english')]\n",
        "print(\"Filtered Words:\", filtered_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usk6SGqrK8Qw",
        "outputId": "44c2fce2-6443-466a-edc9-1f46b989b286"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtered Tokens: ['Dr.', 'Smith', ',', 'traveled', 'Washington', ',', 'D.C.', 'Jan.', '5th', 'cutting', '-', 'edge', 'NLP', 'conference', ',', 'keynote', ',', 'explained', 'advancements', 'tokenization', 'techniques', '—', 'particularly', 'implemented', 'NLTK', 'spaCy', '(', 'e.g.', ',', 'handling', 'abbreviations', 'like', '\"', 'Dr.', '\"', '\"', 'e.g.', '\"', 'seamlessly)—are', 'transforming', 'text', 'analysis', '.']\n"
          ]
        }
      ],
      "source": [
        "# spaCy Stopwords Filtering\n",
        "doc = nlp(long_text)\n",
        "filtered_tokens = [token.text for token in doc if not token.is_stop]\n",
        "print(\"Filtered Tokens:\", filtered_tokens)\n"
      ]
    }
  ]
}